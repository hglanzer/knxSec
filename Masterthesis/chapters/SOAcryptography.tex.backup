\section{Cryptography}

The tool to achieve information security is cryptography.
Cryptography \footnote{classical greek for \textit{krypt\^{o}s}: \textit{concealed}}
is the science of encrypting information. The evolution of cryptography was no linear process. Ciphers were used independently in different
places, were forgotten and disappeared when the corresponding civilization died. Nevertheless,
basics are found thousands of years ago, therefore a short time table for prominent events is presented:

One of the oldest witnesses for cryptography are hieroglyphs used in Egypt about 2000 B.C., forming the predecessor
of a simple substitution cipher. 500 B.C., the "skytale" was used by greek and spartan military leaders, performing a transposition cipher. Another classical
example was the "Caesar Cipher", used by its inventor about 100 B.C. to hide information by replacing every letter of the alphabet by a letter some fixed number down the alphabet,
thus performing a substitution cipher. Ahmas al-Qalqashandi, an egypt writer, introduced the frequency analysis, a method for breaking substitution ciphers,
in the 14th century. About 300 years later, the "Geheime Kabinets-Kanzlei" in Vienna routinely intercepts, copies and 
 re-seales diplomatic correspondence to embassies, and manages to decrypt a great percentage of the ciphertexts. In the beginning of the 20th century, the 
 first cryptographic device called "Enigma" \footnote{classical greek for "riddle"} is patented for commercial use and is later used in World War 2 by german troops for 
 military communication. Successful attacks against the "Enigma" cipher are demonstrated by polish mathematicians even before outbreak of the war, and systematic
 encryption of "Enigma" - based ciphertexts are conducted in Bleatchley Park, U.K., by using so called "Turing-Bombs", giving the allies invaluable advantages.
The second half of the 20th century brings the introduction of public key cryptography with it: in 1976 Whitfield Diffie and Martin Hellman specify a 
protocol for key exchange, based on a public key system developed by Ralph Merkle, and one year later, the RSA public key encryption is found by the american
mathematicians Rivest, Shamir and Adleman.


Cryptography is basically the art of hiding information by turning cleartext
data into a 
pseudo-random looking stream or block of bits, called ciphertext, using some kind of
\textit{key}. This process is called \textit{encryption}. Key, clear- and cipher text all are strings built from the alphabet $\mathcal{A}$. 

\begin{itemize}
 \item $\mathcal{A}$ is a finite set, denoting the alphabet used, for example
 $\mathcal{A} = \{0, 1\}$
 \item $\{0, 1\}^n$ denotes the set of all possible strings with length $n$
 \item $\mathcal{M}$ is the message space, consisting of all strings that can be built with the 
 underlying alphabet
 \item $\mathcal{C}$ is the ciphertext space, also consisting of the strings from 
 the alphbet
$\mathcal{A} = \{0, 1\}$

\item $\mathcal{K}$ is called keyspace, also built from the alphabet. Every element
 $e \in \mathcal{K}$ is called a key and determines the function $\mathcal{M} \rightarrow \mathcal{C}$.
 This function, $E_e$ is called the \textit{encryption function}. 
  \begin{center}
 $ciphertext = E_e(e, cleartext)$
  \end{center}
\end{itemize}

Unauthorized parties - lacking the used key - should, by looking at the ciphertext, learn
absolutely nothing about the hidden cleartext beside the length of the origin message. Authorized parties, on the other hand, are
able to retrieve the original data out of the ciphertext by using the key with polynomial work, thus reversing
the encryption. This reversing process is called \textit{decryption}.

\begin{itemize}

 \item For every key $d \in \mathcal{K}$, $D_d$ denotes the function from $\mathcal{C} \rightarrow
  \mathcal{M}$, and is called \textit{decryption function}.
  \begin{center}
  $cleartext  = D_d(d, ciphertext)$
    \end{center}
\end{itemize}

The keys $e$ and $d$ are also referred to as \textit{keypair}, written $(e,d)$. 
If it is computationally easy to derive the private key $e$ from the public key $d$(in most cases $e = d$), the encryption scheme
 is called \textit{symmetric}, otherwise the scheme is called \textit{asymmetric}.

Combining this properties yields a cipher or \textit{encryption scheme}) defined over $\mathcal{(K,M,C)}$, which is a pair of \textit{efficient}
 \footnote{"runs in polynomial time"} algorithms s.t.
 \begin{center}
   $\mathcal{K} \times \mathcal{M} \rightarrow \mathcal{C}$
   \\
   $\mathcal{K} \times \mathcal{C} \rightarrow \mathcal{M}$
 \end{center}

 The correctness property ensures for every pair of $(e,d) \in \mathcal{K}$ and for every message $m \in \mathcal{M}$ that encryption is reverseable, i.e. 
 it must hold that 
 \begin{center}  
 $ m = D_d(d, (E_e(e, m))$
  \end{center}

\subsection{Kerckhoff's Principle}

When designing ciphers, a fundamental question is what components of it must be protected from public knowledge, and what parts can be published without
compromising the security of the system. A cipher is considered secure if it is not breakable by an adversary in a reasonable time frame \cite{handbook1}, where
this time frame is a function of the useful timespan of the protected data. This synonymously means that an adversary must spend exponential work.
It follows that \textit{every} cipher can be broken in principle by
mounting the "brute-focrce" attack, searching the correct $n$-bit key in the exponential big key space $2^n$. Thus, such an exhaustive search must be rendered impracticable by 
using a suitable large key space to obtain a secure cipher.

The dutch cryptographer Auguste Kerckhoff added some additional rules for designing a secure cipher.
According to \textit{Kerckhoff's Principle} stated 1883, among other properties, a secure system should not rely on the secrecy of
its components, the only part that should be kept secret is the key alone.  

Mapped to the definitions above, the sets $\mathcal{M, C, K}$, as well as the
transformation functions $E_e$ and $D_d$, must not secret. The only thing that has to be kept private is the keypair $(e, d)$.

This separation of key and algorithm allows the publication of the basic cipher methods, benefiting from peer review. The contradicting approach by trying
to hide the inner workings from public to increase security is also known as "Security by Obscurity".
\\

Another definition of a secure cipher was introduced by Shannon in 1949 \cite{6769090}, viewed from a communication-theory point of view. Depending on the
message space, there is a finite number of possible cleartext messages, each occurring with its own \textit{a priori} probability. These messages are encrypted
and sent to the receiver. An eavesdropper, intercepting messages, can calculate the \textit{a posteriori} probabilities for all possible cleartext messages, 
leading to the observed cipher text. If booth probabilities are the same, the attacker has learned absolutely nothing from intercepting the cipher text, which
is defined by Shannon as \textit{perfect secrecy}. A prerequisite for a perfectly secure cipher is that the key space is at least as big as the message space.
Otherwise there will exist cleartext messages which are mapped to the same cipher texts, and thus a priori and a posteriori probabilities will change.
\\

Because all cryptographic schemes rely on the generation of random numbers, a short introduction to probabilistic theory and \gls{prng} is given,
followed by a introduction to the most important representatives for symmetric and asymmetric ciphers.

\section{Randomness and Probabilistic Theory}

A basic requirement of all cryptographic schemes is the availability of randomness. \textit{Entropy} is the unit of the unpredictability of a process, and was
also defined by Shannon. The higher the predictability, or in other words, the more likely an event, the lower its entropy. Flipping a "fair" coin is a canonical 
example of a process with maximum entropy, because every coin flip hsa a probability of $\frac{1}{2}$, and all flips are independent from each other \cite{1621063}.
If obtaining heads of the coin is viewed as a logical "0" and tails as a logical "1", a binary string of arbitrary length can be built, where the probability of all possible
strings of same length is equal, as shown in figure \ref{fig:uniform}, yielding a \textit{uniform distribution}. 

The importance of random numbers in cryptography is founded on the nature of the cipher used, as will be shown in the next sections. For example,
stream ciphers generate a keystream which is used
for encryption. If the keystream is predictable by an adversary, the security of the cipher is reduced. Similar arguments are valid for block ciphers, which often
rely on an initial value called \gls{iv} for encryption. As a last example, many protocols rely on determining a random prime number. Again, if such a prime number
can be narrowed down within some boarders, this fact may weaken the encryption process.

A fundamental problem in generating random numbers by utilizing computing devices is the deterministic nature of an algorithm:
\\

\textit{"Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin."} \footnote{John von Neumann, 1951}
\\

Such numbers are therefore called \textit{pseudo}random. Lots of cryptographic products suffered serious flaws because of relying on a broken \gls{prng}. A 
historical example of such a broken random number generator, outputting biased (i.e., not uniformly distributed values) was "RANDU", invented by IBM in the
1960s. 
The generator belongs to the class of multiplicative congruential algorithms as proposed by Lehmer \cite{MR0044899}, which can in principle generate random
numbers of sufficient quality, \textit{if} the correct parameters are chosen.
Random values can be obtained after setting an initial value for $I_0$, called \textit{seed}, and repeatedly executing the calculation

\begin{center}
 $I_{j+1} = 65539 * I_j \pmod{2^{31}}$
\end{center}

One problem 
is that consecutive values generated by RANDU are not independent, which can be seen in figure \ref{fig:randu}. To obtain the plot, 10000 uniformly distributed 
random numbers were chosen as initial seeds for $I_i$ and plotted as x-values. $I_{i+1}$ served as y- and $I_{i+2}$ as z-values. While one would suspect that all points
would be equally distributed in space, a clear pattern is visible, indicating that the values are correlated.

To assess the quality of a \gls{prng}, beside of such spectral tests lots of additional tests are available, see \cite{nistRAND} for details.

To encounter the shortcomings of a \gls{prng}, a \gls{trng} uses a natural process as non-deterministic data source, for example
thermal noise of a semi conductor, cosmic noise from space or digital oscillators.

The used hardware platform, the RapsberryPi, offers a hardware number generator - the quality of its provided random numbers will be subject
to various statistical tests, see chapter \ref{FIXME} for the results.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/uniform}
    \caption{Uniform Distribution of binary string of length 3}
    \label{fig:uniform}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/randu}
    \caption{Spectral Plot of RANDU output}
    \label{fig:randu}
\end{figure}


\section{Symmetric vs. Asymmetric Cryptography}

As stated above, two very fundamental differences regarding the key used in a cryptographic system can be found. Symmetric ciphers, where in the most cases
the same key is used for encryption and decryption, outperform its asymmetric counterparts in regards of data throughput by a factor of about 1000 \cite{5412055}.
Additionally, they need shorter keys to achieve the same level of security - both arguments encourage it's use in embedded devices because of its less computing
and memory demands.

The big disadvantage of symmetric ciphers is that the key must be known to sender
and receiver of the message \textit{before} secure communication can take place. This constitutes some kind of chicken-egg problem: to be able to send encrypted
data, the key must be distributed, i.e. a secure channel has to be setup first, but the key can obviously not be sent before this secure channel exists.
\\

Asymmetric or public key cryptography solves the problem of key distribution by using two different keys, belonging to the same key pair: the \textit{private}
key must be be protected from disclosure, while the \textit{public} key can be published without harming security. For encryption, the public key of the receiver
is used, who in turn will use his private key to decrypt the message. 

To be able to take benefit from the advantages of booth schemes, a hybrid approach is possible: at first, public key cryptography is used to negotiate a symmetric session
key, which then can be used to encrypt the actual, sensitive data.

\subsection{Stream Ciphers}

Stream ciphers belong to the family of symmetric ciphers, thus $e_i = d_i$.
For encryption, stream ciphers take arbitrary long messages (from the message space $\mathcal{M}$), and encrypt
them to the corresponding ciphertext(out of the ciphertext-space $\mathcal{C}$), by applying
one digit of the message to one digit of the key. It is valid to say that a streamcipher is a block cipher with blocklength 1.

\begin{itemize}
 \item A keystream is a sequence of symbols $e_0, e_1, ..., e_n$, all taken from the keyspace $\mathcal{K}$
\end{itemize}

The encryption function $E_e$ performs the substitution $c_i = E_e(e_i, m_i)$, producing one encrypted symbol at a time. Analogously,
the decryption function inverts this substitution: $m_i = D_d(d_i, c_i)$.

\subsubsection{The Vernam Cipher} 

This cipher, also called \gls{otp}, was invented by Gilbert Vernam in 1918, and belongs to the family of polyalphabetic stream ciphers,
which means that every character of the origin message is mapped to another character of the same alphabet. In contrast to a monoalphabetical cipher,
there is no fixed mapping between the input and output characters.
The substitution is achieved by generating a keystream and by executing 
a bit-wise XOR operation, as defined in table \ref{table:xor}, of key and message.

\begin{center}
\begin{tabular}{ l c | r }
 \label{table:xor}
   &  & $\bigoplus$ \\ \hline
  0 & 0 & 0 \\
  0 & 1 & 1 \\
  1 & 0 & 1 \\
  1 & 1 & 0 \\
\end{tabular}
\end{center}

Obviously, the security of the cipher heavily depends on the quality of the \gls{prng}. If a truly random source is used to generate the key stream, this cipher
has perfect secrecy. Nevertheless, the cipher can be completely broken if the same key is used for encrypting more than one cleartext message, allowing to mount
an attack based on frequency analysis.
Imagine an attacker is able to intercept a specific amount of different ciphertexts, all encrypted with the same key. Pairwise xor'ing of the ciphertexts
yields the xor-combination of the corresponding cleartexts, because
\begin{center}
 $m_1 \bigoplus m_2 = (c_1 \bigoplus k) \bigoplus (c_2 \bigoplus k) = c_1 \bigoplus c_2 \bigoplus k \bigoplus k = c_1 \bigoplus c_2 \bigoplus 0 = c_1 \bigoplus c_2$
\end{center}

Whenever the same character is present in two different ciphertexts at the same position, the result of the xor operation will be 0x00, allowing to draw
inferences about the language used. By utilizing frequency analysis, the used key can be determined position by position with effort bounded by $O(n^2)$.

\subsubsection{Stream Ciphers based on \gls{lfsr}}

An disadvantage of the Vernam cipher is that a key of equal length as the message is necessary. To mitigate this problem, a \gls{lfsr} can be used to generate
a key of proper length from a much short, initial key.1

\subsection{Block Ciphers}

Here, the cleartext-message is broken into equally sized parts, which are then encrypted block by block. While streamciphers are not parallelizable
by nature, there exist methods to speed up en- and decryption by splitting the message respectively ciphertext first as normal, and then process them in
parallel\footnote{Counter Mode, see \ref{confidentiality}}. A disadvantage of block ciphers is that it may be necessary to pad the last block to the used block size. 
\\
\\
Three main groups of block cipher exists:
\begin{itemize}
 \item Permutation Blockciphers
 \item Substitution Blockciphers
 \item Product Blockciphers
 \item Feistel Networks
\end{itemize}

\subsubsection{Permutation Blockciphers}

\subsubsection{Substitution Blockciphers}

\subsubsection{Product Blockciphers}

\subsection{Feistel Networks}

\subsection{Stream Ciphers}

\subsection{Block Ciphers}

\subsection{Confidentiality}\label{confidentiality}

\subsubsection{Cipher Block Chaining - CBC}

For encryption, CBC needs as underlying block cipher which is invertible, so a PRP has to be used. 
As usal, the message has to be broken into blocks, suitable for the block cipher. 

\begin{center}
$ C_0 = E(k, (M_0 \bigoplus IV ) )  $
\\
$ C_1 = E(k, (M_1  \bigoplus C_0) ) $
\\
$...$
\\
$ C_i = E(k, (M_i \bigoplus C_{i-1} ) )  $
\end{center}

To reverse the process, i.e. decrypt the message:

\begin{center}
$ M_0 = D(k, C_0) \bigoplus IV $
\\
$ M_1 = D(k, C_1) \bigoplus C_0 $
\\
$...$
\\
$ M_i = D(k, C_i) \bigoplus C_{i-1} $
\end{center}

The initialization vector, IV, does not have to be kept private, in fact the receiver of the encrypted message must know this value,
either implicitly or explicitply. The first is possible if this IV is some kind of counter or sequence number, which both sender
and receiver know. This way, replay attacks can be detected if some kind of MAC is used too, see chapter \ref{authEncrypt}.
If the IV is chosen by random, or cannot be calculated by the receiver, it \textbf{must} be sent along with the message itself as
very first block, increasing the overhead, which can be problematic for short messages(for example, consider 1 block messages, consisting
of 16 databytes - the IV therefore doubles the size of the data to be sent).

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/"CBC encrypt".png}
    \caption{Cipher Block Chaining for encrypting messages}
    \label{fig:cbc_encrypt}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/"CBC decrypt".png}
    \caption{Cipher Block Chaining for decrypting messages}
    \label{fig:cbc_decrypt}
\end{figure}

\subsubsection{Counter Mode - CTR}

\subsection{Authenticity}\label{authenticity}

\subsubsection{OCB}

\subsubsection{Cipher Block Chaining - CBC}


\begin{figure}\label{cbcMAC}
    \centering
    \includegraphics[width=1\textwidth]{figures/"CBC MAC".png}
    \caption{Cipher Block Chaining for generating a MAC}
    \label{fig:cbc_MAC}
\end{figure}

\begin{figure}\label{cbcMACFlags}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/"CBC IV Flags".png}
    \caption{Flag Field of CBC IV}
    \label{fig:cbc_Flags}
\end{figure}

\section{Authenticated Encryption}\label{authEncrypt}

\subsection{CCM}

CCM\footnote{http://tools.ietf.org/html/rfc3610}, short for \textit{Counter with CBC-MAC} combines CBC for authentication and CTR mode for encryption.
CBC generates the MAC for the message first, appends this MAC to the cleartext data and afterwards encrypts data + MAC with counter mode, thus using a
\textit{MAC-then-Encrypt} scheme. The only
supported block size is 128-bit blocks, so it is possible, but not mandatory, to use 128-bit AES as underlying block cipher.
\\
Two application dependent parameters have to be fixed first: 
\begin{itemize}
 \item M: Number of octets in the MAC field. A shorter MAC obviously means less overhead, but it also makes it easier for an adversary to guess the correct
 value of a MAC, so valid values are $M \in \{4, 6, 8, 10, 12, 14, 16\}$. FIXME: shorter MACs insecure, border=4 ? 
 \item L: Number of octets in the length field. This is a trade-off between the maximum message size and the size of the nonce. Valid values are $2 \leq L \leq 18$.
 For example, when setting $L = 2$, 2 bytes are reserved for the length field, which means that the biggest message that can be encrypted is of size 64kB. The actual
 length of the message is filled into the field named 'length(msg)', as shown in figure \ref{fig:cbc_MAC}.
\end{itemize}

Both parameters are encoded in the very first byte of the first message block, thus reducing the possible maxium size of the nounce, as shown in figure \ref{fig:cbc_Flags}.
Bit 6 of the length field is set to 1 if additional authenicated data(FIXME) are sent, and bit 7 is reserved and set to 0.


\subsubsection{Generating the MAC}

As shown in chapter \ref{authenticity} in figure\ref{fig:cbc_MAC}, the first message block $M_0$ is xor'd with a nonce or initialization vector(IV, see figure
\ref{fig:ccrMacIV}), which \textbf{must be unique per key}.FIXME
The result of the xor operation is then feed to the block-cipher to get the first cipherblock $C_0$. The encrypted data $C_0$ gets xor'd with the next message block $M_1$, and this
result becomes the input for the block cipher, and so on, iterating over all $n$ message blocks to determine the tag $t$:

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/"CCM CBC IV".png}
    \caption{IV for CBC MAC}
    \label{fig:ccrMacIV}
\end{figure}


\begin{center}
 $C_0 = F(k, M_0 \bigoplus IV )$
 \\
 $C_1 = F(k, M_1 \bigoplus C_1) $
 \\
 $...$
 \\
 $C_n = F(k, M_n \bigoplus C_{(n-1)})$
 \\
\end{center}

The resulting tag $t$ can be truncated, corresponding to the chosen MAC size $M$:
\begin{center}
  $t = C_n[M:0]$, with $M \in \{4, 6, 8, 10, 12, 14, 16\}$
\end{center}
which means that the tag $t$ consists of the least significant $M$ bytes of the output of the last encryption block.

\subsubsection{Encrypting Data and MAC}

Counter-mode is used for encrypting the actual payload and the concatenated, CBC mode generated MAC.
Thus, authenticated encryption is achieved in a manner also called 'mac-then-encrypt'. While authenticated
encryption modes implementing this ordering(generate mac first, then encrypt data and mac) \textit{may}
be vulnerable to padding oracle attacks(FIXME), counter mode effectively avoids these simply because
there is no padding needed, as will be shown.

Counter mode implements a weaker form of the one time pad by generating a keystream of sufficient
length, and then xoring the keystream with the data itself, as shown in figure \ref{fig:ctr}.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/CTR.png}
    \caption{CTR Encryption}
    \label{fig:ctr}
\end{figure}

First, keyblocks with 16 byte length each are generated by encrypting the nounce, a flag and a counter with the key. These 
keyblocks are then concatenated and trimmed to the proper length(=length of the message to encrypt). This obtained keystream
is then bitwise xored with the cleartextmessage(which consists of the data and the MAC), yielding the final encryption.


\subsubsection{Decryption and Authenticity Check}

\subsubsection{Attacks on CCM}

FIXME: meet in the middle attack, siehe rfc 3610

\section{Public Key Cryptography}

Public Key Cryptography solves the problem of establishing a secure channel by using an unsecured one.
Here sender and recipients use two different keys: one for encryption, called \textit{public key}, the other
for decryption, called \textit{private key}. This key pair belongs together, hence this scheme is also called \textit{asymmetric} encryption. A key requirement
is that it must be hard
to derive the decryption key from the encryption key. This behavior is achieved by some kind of public known one-way function where it is computationally
easy to calculate the result of $f(x) = y$, but only given $y$, it is computationally - in the domain of processing power and/or memory - hard
to reverse this function to get $x$, although the reverse function may exist in mathematical sense. This is even a desired property. Otherwise
it may facilitate to find the argument that led to the output, i.e. take the constant function, where it is trivial to find the argument.
By that fact, the encryption or public key can be published in some sort of dictionary without compromising the private key. An entity wanting to
send an encrypted message to a receiver can then look up the receiver's public key, encrypt the message and send the resulting
ciphertext to the recipient, who then can decrypt the message. It is remarkable that any algorithm establishing public keys must authenticate it's 
participants, or it will be vulnerable to man-in-the-middle attacks.

\subsection{Discrete Logarithm Systems}

Whitfield Diffie and Martin Hellman were the first who proposed a way to solve the problem for key-exchange by introducing the concept of 
a public-key cryptography when they published their paper \textit{New Directions in Cryptography} back in 1976. The security of this concept
is based on the hardness of the \textit{Discrete Logarithm Problem}. 

With the original Diffie-Hellman algorithm, 2 entities - $A$ and $B$ - use exponentiation over finite fields to agree on a shared secret, which
then can be used parametrize a block or stream cipher. The first step for booth entities is to agree on the set of parameters $\{p, q, g\}$, where $p$ is a 
large prime, $q$ is a prime divisor of $p-1$, and $g$ is a generator of the cyclic group ${Z_p}^*$ in the range $[1, p-1]$. These parameters are not secret and
can thus be sent over an unsecured channel.
Additionally, each entity randomly chooses an integer $x$ from the interval $[1, q-1]$, and calculates the value  $y = g^x \pmod p$. $x$ is the private key,
$y$, which is computationally easy to calculate, is the public key. $A$ sends its public key $y_A \equiv g^{x_A} \pmod p$ to $B$, and $B$ its public key
$y_B \equiv g^{x_B} \pmod p$ to $A$. Due to the characteristics of exponentiation, $A$ and $B$ can now easily derive the shared secret by using it's counterpart's
public key and raising it to the power of it's own private key in the domain of ${Z_p}^*$:

$k_B \equiv {y_A}^{x_B} \equiv {g^{x_A}}^{x_B} \equiv g^{x_A*x_B} \pmod p = k_A \equiv {y_B}^{x_A} \equiv g{^{x_B}}^{x_A} \equiv g^{x_B*x_A} \pmod p $

An eavesdropper that intercepts the initial sent paramter set $\{p, g, q\}$ and the public keys $y_A$ and $y_B$ and that wants to calculate the shared secret
$k_A = K_B$  must therefore the Discrete Logarithm Problem. FIXME: security analysis of DLP

\subsection{Diffie-Hellman based on Elliptic Curves}

\subsection{RSA}

\section{Attacks on Ciphers}

\subsection{Passive Attacks}

timing attacks - constant time computation

\subsection{Active Attacks}


BLABLA:
\\

Such a cipher as defined above provides confidentiality, i.e. it ensures that only authorized parties are able to decrypt the message. This leads to other
problems, namely how to determine who is authorized, i.e. how to provide authenticity, and how to assure that the message was not altered when, i.e. how to 
provide integrity. It turns out that such a cipher is suitable for these purposes

A system is an entity that interacts with other entities, which constitute the environment for the system and
can be other systems, humans or the physical world \cite{1335465}. Fundamental properties of communication systems
are \textit{functionality, performance, security and dependability}. The system provides services to the user(s) 
of the system through it's service interface, described by the functional specification. Whenever the provided service
deviates from correct service a system failure occurs. 
An informal definition of a dependable system is a system which delivers a service that can be justifiable trusted. More formally,
dependability consists of the following attributes:
\textit{Availability}, which means that the system is ready for correct service, \textit{reliability}, the continuity of correct service,
\textit{safety}, i.e. the avoidance of catastrophic consequences \textit{integrity}, s.t. the system cannot be modified in an unwanted manner
and \textit{maintainability}, so that the system can be repaired in the case of a failure.

In case of a secure system, another important property is \textit{confidentiality}, which means that no information is disclosed to unauthorized 
entities.
To achieve 

\subsection{Finite fields}

\subsection{One Way functions}

The idea for this concept was formulated for the first time in the year 1874 by William Stanley Jevons in his book
'The Principles of Science'(page 144).

\section{Propabilistic Theory}



FIXME: comutationally secure vs. unconditionally secure, i.e. one time pad(perfect secrecy?)
FIXME: MERKLE puzzles
